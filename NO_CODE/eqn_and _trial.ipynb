{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`The diagram DNN optimization landscape, is the loss function`\n",
    "\n",
    "$Loss = \\frac{1}{m} \\cdot \\sum_{i=0}^{m} (Y_i - f(x_{i1},x_{i2},..x_{iN}))^2$\n",
    "\n",
    "$Loss = g(w_1, b_1, w_2, b_2,...w_N, b_N) + c$\n",
    "\n",
    "` Loss is a function of neural network weights & bias terms & a constant$.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Now let's look at the update rule`\n",
    "\n",
    "`Update Rule`\n",
    "\n",
    "$w_j^{i+1} = w_j^{i} - \\alpha \\cdot \\frac{\\partial g(...)}{\\partial w_j}$\n",
    "\n",
    "$b_j^{i+1} = b_j^{i} - \\alpha \\cdot \\frac{\\partial g(...)}{\\partial b_j}$\n",
    "\n",
    "$\\forall j \\epsilon \\{1, 2, ... N\\}$; \n",
    "i-th iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$dw_j = - dt \\cdot  \\frac{\\partial g(...)}{\\partial w_j}$\n",
    "\n",
    "$\\frac{dw_j}{dt} = - \\frac{\\partial g(...)}{\\partial w_j}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ODE ~ 2 state variables**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\frac{dx}{dt} = a\\cdot x + b\\cdot y$\n",
    "\n",
    "$\\frac{dy}{dt} = c\\cdot x + d\\cdot y$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import multiprocessing as mpc\n",
    "import numpy as np\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1818)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 15, 10, 15, 8, 14, 14, 11, 7, 9]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def sum(a: int, b: int):\n",
    "    global g_arr\n",
    "    g_arr.append(a+b) \n",
    "\n",
    "join = [] # This memory is part of main thread.\n",
    "g_arr = mpc.Manager().list() # This memory is shared\n",
    "for _ in range(10):        \n",
    "    p = mpc.Process(target = sum, args=(np.random.randint(1, 10), np.random.randint(1, 10)))\n",
    "    join.append(p) \n",
    "    p.start()\n",
    "\n",
    "for p in join:\n",
    "    p.join()\n",
    "\n",
    "print(list(g_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "M, dim = 1024, 1 \n",
    "batch_size = 32\n",
    "\n",
    "X = torch.tensor(np.random.normal(size=(M, dim)), dtype = torch.float32)\n",
    "Y = torch.tensor([[1,0] if x > 0 else [0,1] for x in X], dtype = torch.float32)\n",
    "Xtr, Xtest, Ytr, Ytest = train_test_split(X, Y, test_size = 0.3, random_state = 1919)\n",
    "train_dataset = TensorDataset(Xtr, Ytr)\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle = True)\n",
    "\n",
    "for xb, yb in train_loader:\n",
    "    print(xb, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = [[_ for _ in range(3)] for __ in range(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 2], [0, 1, 2]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: [(1, 1), (4, 2), (9, 3), (16, 4), (25, 5)]\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "# Define the function to be run in parallel\n",
    "def worker_function(x):\n",
    "    return x * x, x\n",
    "\n",
    "def main():\n",
    "    # Create a list of inputs for the worker function\n",
    "    inputs = [1, 2, 3, 4, 5]\n",
    "\n",
    "    # Create a Pool of worker processes\n",
    "    with multiprocessing.Pool(processes=4) as pool:\n",
    "        # Map the worker function to the list of inputs\n",
    "        results = pool.map(worker_function, inputs)\n",
    "\n",
    "    # Print the results collected from the worker processes\n",
    "    print(\"Results:\", results)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
